<h2 align="left">
  üë©üèª‚Äçüíª Aplicando o resultado nos dados de teste e salvando os resultados
</h2>

Voc√™ avan√ßou muito no seu projeto e, para fechar com chave de ouro, voc√™ ir√° aplicar o modelo de classifica√ß√£o escolhido aos dados de teste e salvar seus resultados.

Lembra que voc√™ separou uma parte dos dados para usar como teste? Pois bem, √© hora de testar o seu modelo neles e ver como ele se comporta em dados que ele nunca viu antes.

E ah! N√£o se esque√ßa de serializar o seu modelo no final desse processo. Ou seja, gerar um arquivo com seu modelo salvo para que possa ser carregado depois em outros projetos ou compartilhado com outras pessoas.

Para salvar o seu modelo, existem duas bibliotecas muito famosas no Python que podem ajudar, Joblib e a Pickle. Para salvar seu modelo usando a Joblib, √© s√≥ adicionar a linha de c√≥digo joblib.dump(modelo, nome_arquivo.sav). Se for em Pickle, √© s√≥ adicionar pickle.dump(modelo, nome_arquivo.pkl).

#

### Extras

Voc√™ pode me perguntar: qual seria o pr√≥ximo passo depois de criar um modelo? Bom, de fato, a cria√ß√£o do modelo √© apenas uma parte do processo. Com o modelo pronto, voc√™ vai precisar implementar em produ√ß√£o (deploy), para que possa ser usado em aplica√ß√µes em um projeto real. √â importante decidir como as pessoas usar√£o o modelo para realizar predi√ß√µes ou identificar padr√µes.

Esse [post](https://blog.somostera.com/data-science/deploy-o-que-e?utm_term=&utm_campaign=ad-cpa-tofu-insti_aniver-6a&utm_source=adwords&utm_medium=ppc&hsa_acc=9763069323&hsa_cam=17892248829&hsa_grp=&hsa_ad=&hsa_src=x&hsa_tgt=&hsa_kw=&hsa_mt=&hsa_net=adwords&hsa_ver=3&gad=1&gclid=CjwKCAjwxr2iBhBJEiwAdXECwwutY8s9TfI2vmcnICo30ZX1macXqW-W9oEQgNwFUBLPzTKZpcZFVRoCzdQQAvD_BwE) d√° uma boa introdu√ß√£o sobre deploy de modelos. E esse [artigo](https://medium.com/data-hackers/como-eu-fiz-o-deploy-do-meu-primeiro-modelo-de-machine-learning-9b416d9abc51) mostra uma aplica√ß√£o na pr√°tica.

Outro ponto importante ap√≥s a cria√ß√£o de um modelo √© o modelo de retreinamento. Pergunte-se: o modelo ainda √© v√°lido para novas cargas de trabalho? Lembre-se de que aprendizado de m√°quina √© muito experimental, ent√£o √© aqui que voc√™ dever√° rastrear seus dados e experimentos, verificando o desempenho do modelo com base em m√©tricas, quantas vezes for necess√°rio.

Al√©m disso, voc√™ ver√° que as suas previs√µes podem come√ßar a envelhecer ou que os dados podem ficar desatualizados, ou, at√© mesmo, novos padr√µes podem surgir, tornando o modelo original incapaz de capturar essas mudan√ßas.

Isto e muitas outras diretrizes s√£o mencionadas no artigo "Rules of Machine Learning", escrito por Martin Zinkevich, engenheiro de software no Google. [Recomendo demais essa leitura](https://developers.google.com/machine-learning/guides/rules-of-ml?hl=pt-br&utm_source=ActiveCampaign&utm_medium=email&utm_content=%237DaysOfCode%20-%20Machine%20Learning%207%2F7%3A%20Aplicando%20o%20modelo%20nos%20dados%20de%20teste%20e%20salvando%20os%20resultados&utm_campaign=%5BAlura%20%237Days%20Of%20Code%5D(Js%20e%20DOM%20-%203%C2%AA%20Ed%20)%207%2F7#ml_phase_ii_feature_engineering)!

Uma das coisas mais interessantes que ele menciona √©: "[...] √© importante se concentrar em algo que n√£o √© ensinado em nenhuma classe de machine learning: como analisar e melhorar um modelo atual. Isso √© mais uma arte do que uma ci√™ncia, mas existem v√°rios antipadr√µes que podem ajudar a evitar isso." E no decorrer desse t√≥pico, ele mostra algumas boas pr√°ticas, como por exemplo, medir o delta entre os modelos, ou seja, calcular a diferen√ßa entre os novos resultados e a produ√ß√£o. Fica a dica!üòâ
