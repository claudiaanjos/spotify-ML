<h2 align="left">
  ğŸ‘©ğŸ»â€ğŸ’» DivisaÌƒo dos dados e validacÌ§aÌƒo cruzada
</h2>

No desafio de hoje, vocÃª vai trabalhar na divisÃ£o dos seus dados em treino, validaÃ§Ã£o e teste. Essa Ã© uma etapa essencial antes de criar os seus modelos de machine learning.

Mas vocÃª deve estar se perguntando, por que eu vou precisar dividir, nÃ£o Ã© mesmo?! A resposta Ã© simples: para avaliar o desempenho do seu modelo de forma justa. Se vocÃª usar todos os dados para treinar o modelo, nÃ£o terÃ¡ como saber se ele Ã© bom o suficiente para generalizar para dados novos. AlÃ©m disso, essa tÃ©cnica Ã© usada para garantir que o modelo nÃ£o esteja superajustado (overfitting) aos dados de treinamento e que possa funcionar bem em novos dados.

Em resumo, os dados de treinamento sÃ£o usados para treinar o modelo, enquanto que os dados de teste sÃ£o usados para avaliar o desempenho do modelo em dados que ele nunca viu antes. E os dados de validaÃ§Ã£o, sÃ£o usados para ajustar os hiperparÃ¢metros do modelo (parÃ¢metros que melhoram o desempenho do modelo).

Mas como vocÃª pode dividir os dados? Bom, existem vÃ¡rias formas de fazer isso.

Uma delas Ã© a divisÃ£o aleatÃ³ria, que simplesmente separa os dados em trÃªs conjuntos de forma aleatÃ³ria. Geralmente, 70-80% dos dados sÃ£o usados para treino, 10-20% para teste e 10-20% para validaÃ§Ã£o. Essa tÃ©cnica Ã© simples e rÃ¡pida, mas pode nÃ£o ser uma boa escolha quando hÃ¡ desequilÃ­brio de dados.

Outra forma Ã© a validaÃ§Ã£o cruzada, que Ã© usada para avaliar a capacidade de generalizaÃ§Ã£o do modelo em diferentes conjuntos de dados. Ela ajuda muito a evitar o overfitting, que Ã© quando um modelo se ajusta demais aos dados de treinamento, mas nÃ£o generaliza bem para novos dados.

Uma forma comum de validaÃ§Ã£o cruzada Ã© a StratifiedKFold, que Ã© especialmente Ãºtil para conjuntos de dados desbalanceados (e aqui jÃ¡ vai um spoiler do desafio do dia 6 ğŸ‘€).

AlÃ©m disso, apÃ³s a divisÃ£o dos dados, Ã© necessÃ¡rio dividir o conjunto em X e Y. No seu caso, vocÃª terÃ¡ o conjunto de variÃ¡veis explicativas (X), como gÃªnero musical, duraÃ§Ã£o da mÃºsica, instrumentaÃ§Ã£o, etc, e a variÃ¡vel de saÃ­da (Y), que indicarÃ¡ a popularidade da mÃºsica, e que vocÃª quer prever.

EntÃ£o, minha proposta pra hoje Ã© que vocÃª realize a divisÃ£o dos dados utilizando a validaÃ§Ã£o cruzada. E como desafio extra, utilize a StratifiedKFold e compare com outras tÃ©cnicas de divisÃ£o de dados.

Lembre-se que a divisÃ£o de dados Ã© uma etapa muito importante no processo de machine learning e pode afetar significativamente os resultados do seu modelo.

#

### Extras

- Com dÃºvidas sobre a validaÃ§Ã£o cruzada? Veja esse [artigo de introduÃ§Ã£o](https://medium.com/tentando-ser-um-unic%C3%B3rnio/valida%C3%A7%C3%A3o-cruzada-uma-abordagem-intuitiva-697bb001a0ec) e esse [artigo de validaÃ§Ã£o de modelos](https://www.alura.com.br/conteudo/machine-learning-validando-modelos);

- VocÃª pode comeÃ§ar separando seu dataframe em df_train e df_test aplicando o mÃ©todo train_test_split() da [biblioteca Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html);

- Em seguida, a partir do dataframe de treino (df_train), utilize a validaÃ§Ã£o cruzada para separaÃ§Ã£o dos dados em treino e validaÃ§Ã£o. Tente utilizar a classe StratifiedKFold e aplicar um looping para separar os dados.

- Para entender mais sobre o efeito de Overfitting e Underfitting que eu mencionei anteriormente, recomendo a leitura desse [artigo](https://didatica.tech/underfitting-e-overfitting/).
