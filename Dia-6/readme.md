<h2 align="left">
  üë©üèª‚Äçüíª Reamostragem dos dados e ajuste do modelo selecionado
</h2>

Hoje o desafio ser√° realizar a reamostragem dos dados.

A reamostragem √© uma t√©cnica utilizada em machine learning para lidar com desequil√≠brios nos dados. Quando voc√™ tem um conjunto de dados em que uma das classes √© muito menor do que a outra, isso pode afetar a precis√£o do modelo. Nesse caso, a reamostragem √© uma t√©cnica √∫til para equilibrar o n√∫mero de inst√¢ncias em cada classe.

Lembra que, l√° no dia 02, eu comentei sobre o ponto de corte de popularidade? Bom, √© aqui que ele entra de novo. Se voc√™ definiu um ponto de corte de 50, talvez seus dados n√£o estejam t√£o desbalanceados. Mas quando voc√™ sobe o ponto de corte para 80, por exemplo, voc√™ vai perceber que a propor√ß√£o de m√∫sicas populares √© muito menor que m√∫sicas n√£o populares.

√â importante se atentar a isso, pois a consequ√™ncia desse desequil√≠brio √© que o modelo ter√° uma tend√™ncia a dar muitos "alarmes falsos". Ou seja, ele vai responder muito bem √†s entradas para as classes majorit√°rias (n√£o popular), mas ter√° um desempenho inferior para as minorit√°rias (popular).

Oversampling e Undersampling s√£o duas t√©cnicas utilizadas para lidar com dados desbalanceados. Como voc√™ pode ver na imagem abaixo, o undersampling envolve a redu√ß√£o do n√∫mero de observa√ß√µes da classe majorit√°ria. J√° o oversampling consiste em aumentar o n√∫mero de observa√ß√µes na classe minorit√°ria, criando novas amostras ou duplicando as amostras existentes.

Por este motivo, no desafio de hoje, voc√™ precisar√° realizar o balanceamento das classes de popularidade de m√∫sicas.

Utilize no m√≠nimo duas t√©cnicas, para que voc√™ possa comparar os resultados de performance (atrav√©s das m√©tricas) e decidir qual teve um melhor desempenho.

Reamostragem de dados feita? Ok! Ent√£o, agora √© o momento que voc√™ precisa reajustar o seu modelo. Voc√™ precisar√° definir e testar diferentes hiperpar√¢metros para obter a melhor performance.

Os hiperpar√¢metros s√£o par√¢metros do modelo que n√£o s√£o aprendidos durante o treinamento, mas que precisam ser definidos pelo usu√°rio. Exemplos de hiperpar√¢metros incluem o n√∫mero de √°rvores em um modelo de floresta aleat√≥ria, por exemplo.

Encontrando os melhores hiperpar√¢metros do modelo, voc√™ poder√° treinar novamente o seu modelo.

Lembre-se que o objetivo final do projeto √© criar um modelo de machine learning capaz de prever com precis√£o a popularidade de m√∫sicas no Spotify. Ent√£o, n√£o deixe de explorar diferentes t√©cnicas e abordagens para obter o melhor resultado poss√≠vel.

#

### Extras 

- Crie um dicion√°rio com v√°rios modelos para que voc√™ possa aplicar cada t√©cnica sobre cada modelo e obter o melhor.

```
Dicion√°rio dos classificadores
classifiers = {
      "LogisticRegression": LogisticRegression(),
      "KNearest": KNeighborsClassifier(),
      "DecisionTreeClassifier": DecisionTreeClassifier(),
      "Random Forest": RandomForestClassifier()
}
```

- Algumas t√©cnicas que voc√™s podem utilizar para balanceamento de classes s√£o: Distribui√ß√£o Random UnderSampling, Distribui√ß√£o Random OverSampling, Smote (Over-Sampling), H√≠brido (OverSampling e UnderSampling).

- Voc√™ pode utilizar a RandomizedSearchCV para encontrar os melhores hiperpar√¢metros para um determinado modelo. √â uma t√©cnica interessante, pois permite especificar um conjunto de hiperpar√¢metros a serem testados e, ent√£o, realizar uma busca aleat√≥ria para encontrar as melhores configura√ß√µes.

- Para aprofundar no tema "performance de modelos" recomendo a leitura deste post. Nele, voc√™ pode entender a diferen√ßa entre usar a RandomizedSearchCV e a GridSearchCV.

