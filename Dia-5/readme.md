<h2 align="left">
  üë©üèª‚Äçüíª Validando o modelo
</h2>

Hoje vamos falar sobre a valida√ß√£o do modelo de classifica√ß√£o que voc√™ criou para prever a popularidade de m√∫sicas no Spotify.

Utilizar m√©tricas adequadas de valida√ß√£o de modelos de Machine Learning √© crucial em um projeto. O valor delas reflete a qualidade de um modelo, portanto, se forem mal escolhidas, pode ser imposs√≠vel avaliar se o modelo atende aos requisitos necess√°rios.

A avalia√ß√£o de um modelo de classifica√ß√£o √© feita a partir da compara√ß√£o entre as classes preditas pelo modelo e as classes verdadeiras de cada exemplo. Todas as m√©tricas tem o objetivo de medir qu√£o distante o modelo est√° de uma classifica√ß√£o perfeita, por√©m, fazem isto de formas diferentes.
Uma forma simples de visualizar a performance de um modelo √© atrav√©s da matriz de confus√£o, como mostra figura abaixo:

Trazendo para a situa√ß√£o do desafio:

TP: verdadeiro positivo (a m√∫sica √© popular e modelo acertou)
TN: verdadeiro negativo (a m√∫sica n√£o √© popular e o modelo acertou)
FN: falso negativo (o modelo diz que √© popular, mas o valor real √© n√£o popular)
FP: falso positivo (o modelo diz que n√£o √© popular, mas o valor real √© popular)

Al√©m dessa m√©trica, voc√™ pode utilizar outras como a Acur√°cia, que vai mostrar, dentre todas as classifica√ß√µes, quantas o modelo classificou corretamente; a Precis√£o, que indica, dentre todas as classifica√ß√µes de classe Popular que o modelo fez, quantas est√£o corretas; o Recall, que mostra, dentre todas as situa√ß√µes de classe Popular como valor esperado, quais est√£o corretas; e o F1-score, que √© a m√©dia harm√¥nica entre precis√£o e recall.

A escolha da m√©trica depender√° do objetivo do projeto e das caracter√≠sticas do conjunto de dados. Se o objetivo for minimizar os falsos positivos, a precis√£o ser√° a m√©trica mais importante. Se o objetivo for minimizar os falsos negativos, o recall ser√° a m√©trica mais importante.

Desafio lan√ßado! Que tal validar o modelo que voc√™ criou?! 

#

### Extras


- Para gerar o gr√°fico de matriz de confus√£o, voc√™ pode usar o confusion_matrix() dispon√≠vel na biblioteca do Scikit-learn. Al√©m disso, utilize tamb√©m o Seaborn e Matplotlib para ajustar e melhorar seu gr√°fico.

- Na pr√≥pria biblioteca do Scikit-learn voc√™ tamb√©m vai encontrar fun√ß√µes prontas para extrair m√©tricas, como: .accuracy_score(), .precision_score(), .recall_score(), .f1_score().
